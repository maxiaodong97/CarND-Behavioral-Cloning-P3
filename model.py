import csv
import cv2
import numpy as np
import random
import plotly.offline as py
import plotly.graph_objs as go
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.models import Sequential, model_from_json
from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout
from keras.layers.convolutional import Convolution2D
from keras.callbacks import ModelCheckpoint

# path of the csv file that is generated by simulator.
# each csv file is in following format
# center_image_path, left_image_path, right_image_path, steering_angle, throttle, break, speed
CSV_PATH = '/Users/xma/Desktop/sd/driving_log.csv'


# load the data from csv file and split it into training set and validation set.
# note we only load the file path of the image, and load image in data generator only to save the memory
# note we add hard-coded correction of angle for left image and substract correction for right image.
# path: the csv file path
# test_size: percent of validation set.
# @return X_train, X_valid, y_train, y_valid.
def load_data_and_split(path, test_size):
    imagesPaths = []
    measurements = []
    with open(path) as csvfile:
        reader = csv.reader(csvfile)
        for line in reader:
            measurement = float(line[3])
            for i in range(3):
                imagesPaths.append(line[i])
            for correction in [0, 0.2, -0.2]:
                measurements.append(measurement + correction)
    return train_test_split(imagesPaths, measurements, test_size=test_size, random_state=1)


# utility function to print the histogram of steering angle
def histogram(X, xDescription, yDescription, title):
    data = [go.Histogram(x=X)]
    layout = go.Layout(
        title=title,
        xaxis=dict(title=xDescription),
        yaxis=dict(title=yDescription),
        bargap=0.1,
        bargroupgap=0.1
    )
    fig = go.Figure(data=data, layout=layout)
    py.iplot(fig)


# utility function to navigate the image sample from start to end in a training set or validation set.
def plotSomeSamples(X, y, start, end):
    plt.figure(figsize=(20, 15))
    i = 1
    images = X[start:end]
    for image in images:
        plt.subplot(6, 4, i)
        plt.axis('off')
        plt.title("Angle (" + str(format(y[i], '.2f')) + ")")
        i += 1
        plt.imshow(cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB))
    plt.show()


X_train, X_valid, y_train, y_valid = load_data_and_split(CSV_PATH, 0.25)


# utlity function to explore the input data. Please note the training set and test set already randomly shuffled
# during the split call above.
def exploreSamples():
    plotSomeSamples(X_train, y_train, 0, 24)
    histogram(y_train, "Steering angle", "count distribution",
              "Training Set Steering Angle Distribution")
    plotSomeSamples(X_valid, y_valid, 0, 24)
    histogram(y_valid, "Steering angle", "count distribution",
              "Validation Set Steering Angle Distribution")


# training data generator to fit in keras fit_generator function.
# the function returns batch one by one. As input data set is already randomly shuffled by split
def train_data_generator(batch_size):
    train_batch_index = 0
    while True:
        start = train_batch_index * batch_size
        end = (train_batch_index + 1) * batch_size
        if end > len(X_train):
            end = len(X_train)
            train_batch_index = 0
        images, angles = [], []
        for i in range(start, end):
            image = cv2.imread(X_train[i])
            if bool(random.getrandbits(1)):
                images.append(cv2.flip(image, 1))
                angles.append((y_train[i] * -1.0))
            else:
                images.append(image)
                angles.append(y_train[i])
        train_batch_index += 1
        yield np.array(images), np.array(angles)


# validation data geneartor for fit in keras fit_generator function.
# the function returns batch one by one. As input data set is already randomly shuffled by split
def validation_data_generator(batch_size):
    validation_batch_index = 0
    while True:
        start = validation_batch_index * batch_size
        end = (validation_batch_index + 1) * batch_size
        if end > len(X_valid):
            end = len(X_valid)
            validation_batch_index = 0
        images, angles = [], []
        for i in range(start, end):
            image = cv2.imread(X_valid[i])
            images.append(image)
            angles.append(y_valid[i])
        validation_batch_index += 1
        yield np.array(images), np.array(angles)


# construct the CNN deep learning model. according to
# http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf
# the dropout layer is added to avoid over fitting.
def nvidiaModel():
    model = Sequential()
    # lambda layer to normalized input data, pixel value from -0.5 ~ 0.5
    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160, 320, 3)))
    # cropping layer to reduce the noise. Only road part information is useful to make steering decision.
    model.add(Cropping2D(cropping=((70, 25), (5, 5))))
    # 24 5x5 filters, with relu introduce nonlinearity
    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), activation="relu"))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.2))
    # 36 5x5 filters, with relu introduce nonlinearity
    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation="relu"))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.2))
    # 48 5x5 filters, with relu introduce nonlinearity
    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation="relu"))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.2))
    # 64 3x3 filters, with relu introduce nonlinearity
    model.add(Convolution2D(64, 3, 3, activation="relu"))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.2))
    # 64 3x3 filters, with relu introduce nonlinearity
    model.add(Convolution2D(64, 3, 3, activation="relu"))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.2))
    # flatten layer to fully connect layer
    model.add(Flatten())
    # 100 output of full connected layer
    model.add(Dense(100))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.5))
    # 50 output of full connected layer
    model.add(Dense(50))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.1))
    # 10 output of full connected layer
    model.add(Dense(10))
    # dropout layer to prevent overfitting
    model.add(Dropout(0.1))
    # final output of steering angle
    model.add(Dense(1))
    # print the summary of the model
    model.summary()
    return model


# save model to a file
def save_model_to_file(model):
    # serialize model to JSON
    model_json = model.to_json()
    with open("model.json", "w") as json_file:
        json_file.write(model_json)
    # serialize weights to HDF5
    model.save_weights("model.h5")


# load model from a file.
def load_model_from_file():
    # load json and create model
    json_file = open('model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    # load weights into new model
    loaded_model.load_weights("model.h5")
    return loaded_model


# train the model, a checkpoint function is used to save the best fit.
# the best fit is choosed by minumum of validation loss.
# adam optimizer is used, default params: (lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
def train(model):
    checkpoint = ModelCheckpoint('model-{epoch:03d}-{val_loss:.3f}.h5',
                                 monitor='val_loss',
                                 save_best_only=True)
    model.compile(loss='mse', optimizer='adam')
    model.fit_generator(generator=train_data_generator(128),
                        samples_per_epoch=len(X_train),
                        nb_epoch=10,
                        verbose=1,
                        callbacks=[checkpoint],
                        validation_data=validation_data_generator(128),
                        nb_val_samples=len(X_valid))


model = nvidiaModel()

# load weigths from previous training result.
# model.load_weights('model.h5')
train(model)
# model.save_model_to_file()


def plotFlipped(i):
    plt.figure(figsize=(20, 20))
    plt.subplot(2, 2, 1)
    plt.axis('off')
    plt.title("Angle (" + str(format(y_train[i], '.2f')) + ")")
    image = cv2.imread(X_train[i])
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.subplot(2, 2, 2)
    plt.axis('off')
    plt.title("Angle (" + str(format(-y_train[i], '.2f')) + ")")
    image = cv2.imread(X_train[i])
    plt.imshow(cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB))
    plt.show()


plotFlipped(1)

    plotSomeSamples(X_train, y_train, 0, 24)
    histogram(y_train, "Steering angle", "count distribution",
              "Training Set Steering Angle Distribution")
    plotSomeSamples(X_valid, y_valid, 0, 24)
    histogram(y_valid, "Steering angle", "count distribution",
              "Validation Set Steering Angle Distribution")
